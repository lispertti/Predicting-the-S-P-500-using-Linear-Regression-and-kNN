{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adab40cd",
   "metadata": {},
   "source": [
    "# Setup:\n",
    "Importing modules, ensure MatplotLib plots figures inline and prepare a function to save the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b01b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import datetime as dt\n",
    "\n",
    "# For plotting\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#For preprocessing and modelling data\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#validating model\n",
    "from sklearn.metrics import (mean_squared_error, \n",
    "                             r2_score)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b49a222",
   "metadata": {},
   "source": [
    "# Get the data from CSV\n",
    "Reading the file and checking first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SP500_WSJMarkets_Oct2020to2022.csv')\n",
    "df.head(5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f490ae70",
   "metadata": {},
   "source": [
    "### Preprocessing data:\n",
    "-Formatting column \"Date\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format colum Date from Sep 12, 2022 to 2022-09-12\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e8b72b",
   "metadata": {},
   "source": [
    "Two columns are added:\n",
    "<br>-Difference between the highest and lowest prices indicating price variance during the day\n",
    "<br>-Whether a day has been a turning point, this indicates possibility for resistance level, which is commonly used in trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "#difference between columns High and Low\n",
    "df2[\"Hi_Low_Difference\"] = (df2[\"High\"] - df2[\"Low\"])\n",
    "\n",
    "#interphase for the final column of \"Turning_Point\"\n",
    "df2['HigherThanDayBefore'] = df2['Close'] > df2['Close'].shift(periods=-1, freq=None, axis=0)\n",
    "df2['HigherThanDayAfter'] = df2['Close'] > df2['Close'].shift(periods=1, freq=None, axis=0)\n",
    "\n",
    "\n",
    "#comparing the values in two columns created before and checking that everything looks good\n",
    "df2['Turning_Point'] = np.where( df2['HigherThanDayBefore'] == df2['HigherThanDayAfter'] , 1, 0) \n",
    "df2.head(5)\n",
    "\n",
    "df2 = df2.drop(['HigherThanDayBefore', 'HigherThanDayAfter'],axis=1) #deleting extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5331c5c",
   "metadata": {},
   "source": [
    "Now we have a dataset df2 with extra columns \"Hi_Low_Difference\" and \"Turning_Point\", which we use in the prediction process. In column Turning_Point value 1 means that the price was at its turning point on that day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9268f617",
   "metadata": {},
   "source": [
    "# Viewing data\n",
    "Next we'll see how the datapoints are distributed in columns Hi_Low_difference and Turning_Points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ed2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(20,10)) # create a figure with two axes (1 row,2 columns) on it\n",
    "\n",
    "#filtering out only the rows, which have been turning points\n",
    "TP_data = df2[df2['Turning_Point'] == 1]\n",
    "TP_data = TP_data['Close']\n",
    "\n",
    "axes[0].hist(TP_data, bins=30)\n",
    "axes[0].set_title('Turning points',size=15)\n",
    "axes[0].set_ylabel(\"# times prices has turned\",size=15)\n",
    "axes[0].set_xlabel(\"Close prices USD\",size=15)\n",
    "\n",
    "axes[1].scatter(df2['Close'],df2['Hi_Low_Difference'])\n",
    "axes[1].set_title('Difference between highest and lowest price',size=15)\n",
    "axes[1].set_ylabel(\"Difference of the highest and lowest price of the day\",size=15)\n",
    "axes[1].set_xlabel(\"Close prices USD\",size=15)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "save_fig(\"plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59e0c6",
   "metadata": {},
   "source": [
    "From the plots we can see the majority of the turning points and the smallest variability of prices during a day are below 3000 USD, which makes sense because the data is from past five years and therefore lower prices will always be overrepresented in historical data. Because the price of the index is now at around 3600 USD, we are more interested in the values closer to that. Based on the historgram plot there is weak indication of resistance levels between 3000 - 3400 USD approximately and the scatter plot hghlights prices 3400 USD and 3200 USD approximately. These price levels will be taken into account in the section results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b88c745",
   "metadata": {},
   "source": [
    "## Processing data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e3957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a separate dataset\n",
    "data = pd.DataFrame(index=range(0,len(df)),columns=['Date','Close', 'Open', 'High', 'Low', 'Turning_Point', 'Hi_Low_Difference'])\n",
    "\n",
    "for i in range(0,len(data)):\n",
    "    data['Date'][i] = df2['Date'][i]\n",
    "    data['Close'][i] = df2['Close'][i]\n",
    "    data['Open'][i] = df2['Open'][i]\n",
    "    data['High'][i] = df2['High'][i]\n",
    "    data['Low'][i] = df2['Low'][i]\n",
    "    data['Turning_Point'][i] = df2['Turning_Point'][i]\n",
    "    data['Hi_Low_Difference'][i] = df2['Hi_Low_Difference'][i]\n",
    "\n",
    "#making sure that the data is sorted by date\n",
    "data = data.sort_index(ascending=False, axis=0)\n",
    "\n",
    "#setting numerical date as index for Linear Regression\n",
    "data.index = data['Date'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db44b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train, validation and test datasets 60/20/20 %\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, shuffle = True, random_state = 42)\n",
    "\n",
    "train, val = train_test_split(train, test_size=0.25, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5100ce89",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be9b9b2",
   "metadata": {},
   "source": [
    "### Training the model and calculating errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting column Date for Linear Regression to avoid error\n",
    "train_No_Date = train.drop(['Date'],axis=1)\n",
    "\n",
    "#Training data\n",
    "#creating features and target\n",
    "X_train = train_No_Date.drop('Close', axis=1)\n",
    "y_train = train_No_Date['Close']\n",
    "\n",
    "#training the model and predicting using training data\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation data\n",
    "#deleting column Date for Linear Regression\n",
    "val_No_Date = val.drop(['Date'],axis=1)\n",
    "\n",
    "#creating features and target\n",
    "X_val = val_No_Date.drop('Close', axis=1)\n",
    "y_val = val_No_Date['Close']\n",
    "\n",
    "#predicting with validation data\n",
    "predictions_val = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data\n",
    "\n",
    "#deleting column Date for Linear Regression avoiding error\n",
    "test_No_Date = test.drop(['Date'],axis=1)\n",
    "\n",
    "#creating features and target\n",
    "X_test = test_No_Date.drop('Close', axis=1)\n",
    "y_test = test_No_Date['Close']\n",
    "\n",
    "#predicting using test data\n",
    "predictions_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73358e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating errors\n",
    "mse_train_lr = mean_squared_error(predictions_train, y_train)\n",
    "r2_train_lr = r2_score(y_train, predictions_train)\n",
    "mse_val_lr = mean_squared_error(predictions_val, y_val)\n",
    "r2_val_lr = r2_score(y_val, predictions_val)\n",
    "mse_test_lr = mean_squared_error(predictions_test, y_test)\n",
    "r2_test_lr = r2_score(y_test, predictions_test)\n",
    "\n",
    "from tabulate import tabulate\n",
    "errors = [['Training', mse_train_lr, r2_train_lr],\n",
    "['Validation', mse_val_lr, r2_val_lr],\n",
    "['Test', mse_test_lr, r2_test_lr]]\n",
    "print(tabulate(errors, headers=[\"Mean squared error\", \"R2 Score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967fb718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting results\n",
    "#Training set\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "\n",
    "for i in range(2):\n",
    "    ax = fig.add_subplot(1, 2, i+1)\n",
    "    if i == 0:\n",
    "        plt.scatter(train['Date'], y_train, c='black')\n",
    "        plt.title('Actual S&P500 Index')\n",
    "    else:\n",
    "        plt.scatter(train['Date'], predictions_train, c='red')\n",
    "        plt.title('Linear regression prediction over training set')\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel('S&P500 Index')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "#Validation set\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "\n",
    "for i in range(2):\n",
    "    ax = fig.add_subplot(1, 2, i+1)\n",
    "    if i == 0:\n",
    "        plt.scatter(val['Date'], y_val, c='black')\n",
    "        plt.title('Actual S&P500 Index')\n",
    "    else:\n",
    "        plt.scatter(val['Date'], predictions_val, c='red')\n",
    "        plt.title('Linear regression prediction over validation set')\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel('S&P500 Index')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "#Test set\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "\n",
    "for i in range(2):\n",
    "    ax = fig.add_subplot(1, 2, i+1)\n",
    "    if i == 0:\n",
    "        plt.scatter(test['Date'], y_test, c='black')\n",
    "        plt.title('Actual S&P500 Index')\n",
    "    else:\n",
    "        plt.scatter(test['Date'], predictions_test, c='red')\n",
    "        plt.title('Linear regression prediction over test set')\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel('S&P500 Index')\n",
    "    \n",
    "plt.show()\n",
    "save_fig(\"predictions_LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ee216",
   "metadata": {},
   "source": [
    "## K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0718341",
   "metadata": {},
   "source": [
    "### Training the model and calculating errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b849de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using gridsearch to find the best parameter\n",
    "params = {'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "model_KNN = GridSearchCV(knn, params, cv=5)\n",
    "\n",
    "#fit the model and make prediction using training data\n",
    "model_KNN.fit(X_train,y_train)\n",
    "predictions_train_knn = model_KNN.predict(X_train)\n",
    "\n",
    "#print out the number of neighbors used in the model\n",
    "model_KNN.best_params_\n",
    "\n",
    "#predictions using validation data\n",
    "predictions_val_knn = model_KNN.predict(X_val)\n",
    "\n",
    "#predictions using test data\n",
    "predictions_test_knn = model_KNN.predict(X_test)\n",
    "\n",
    "#calculating errors\n",
    "mse_train_knn = mean_squared_error(predictions_train_knn, y_train)\n",
    "r2_train_knn = r2_score(y_train, predictions_train_knn)\n",
    "\n",
    "mse_val_knn = mean_squared_error(predictions_val_knn, y_val)\n",
    "r2_val_knn = r2_score(y_val, predictions_val_knn)\n",
    "\n",
    "mse_test_knn = mean_squared_error(predictions_test_knn, y_test)\n",
    "r2_test_knn = r2_score(y_test, predictions_test_knn)\n",
    "\n",
    "errors = [['Training', mse_train_knn, r2_train_knn],\n",
    "['Validation', mse_val_knn, r2_val_knn],\n",
    "['Test', mse_test_knn, r2_test_knn]]\n",
    "print(tabulate(errors, headers=[\"Mean squared error\", \"R2 Score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting results\n",
    "#Training data\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "\n",
    "for i in range(2):\n",
    "    ax = fig.add_subplot(1, 2, i+1)\n",
    "    if i == 0:\n",
    "        plt.scatter(train['Date'], y_train, c='black')\n",
    "        plt.title('Actual S&P500 Index')\n",
    "    else:\n",
    "        plt.scatter(train['Date'], predictions_train_knn, c='red')\n",
    "        plt.title('kNN Prediction over training set')\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel('S&P500 Index')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "#Validation data\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "\n",
    "for i in range(2):\n",
    "    ax = fig.add_subplot(1, 2, i+1)\n",
    "    if i == 0:\n",
    "        plt.scatter(val['Date'], y_val, c='black')\n",
    "        plt.title('Actual S&P500 Index')\n",
    "    else:\n",
    "        plt.scatter(val['Date'], predictions_val_knn, c='red')\n",
    "        plt.title('kNN Prediction over validation set')\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel('S&P500 Index')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "#Test data\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "\n",
    "for i in range(2):\n",
    "    ax = fig.add_subplot(1, 2, i+1)\n",
    "    if i == 0:\n",
    "        plt.scatter(test['Date'], y_test, c='black')\n",
    "        plt.title('Actual S&P500 Index')\n",
    "    else:\n",
    "        plt.scatter(test['Date'], predictions_test_knn, c='red')\n",
    "        plt.title('kNN Prediction over test set')\n",
    "    plt.xlabel('Years')\n",
    "    plt.ylabel('S&P500 Index')\n",
    "    \n",
    "plt.show()\n",
    "save_fig(\"predictions_kNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8367e30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
